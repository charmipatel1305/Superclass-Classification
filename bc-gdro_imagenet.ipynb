{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.nn import Linear, ReLU, BCEWithLogitsLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, Dropout\n",
    "from torch.optim import Adam,SGD\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from collections import Counter\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler,Subset, WeightedRandomSampler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ImageDataset(Dataset):\n",
    "#     def __init__(self, csv_file, transform=None):\n",
    "#         self.data = pd.read_csv(csv_file)\n",
    "#         self.data.to_string(index=False)\n",
    "#         self.transform = transform\n",
    "#         self.data['Super Class'] = self.data['Super Class'].apply(lambda x: 0 if x == 'benign' else 1)\n",
    "#         label_map = {\n",
    "#             'adenosis': 0,\n",
    "#             'fibroadenoma': 1,\n",
    "#             'tubular_adenoma': 2,\n",
    "#             'phyllodes_tumor': 3,\n",
    "#             'ductal_carcinoma': 4,\n",
    "#             'lobular_carcinoma': 5,\n",
    "#             'mucinous_carcinoma': 6,\n",
    "#             'papillary_carcinoma': 7\n",
    "#         }\n",
    "#         self.data['Sub Class'] = self.data['Sub Class'].map(label_map)\n",
    "\n",
    "        \n",
    "#     def __len__(self):\n",
    "#         return len(self.data)\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         image_path = self.data.iloc[idx, 0]\n",
    "#         image = Image.open(image_path).convert(\"RGB\")\n",
    "#         SuperClass = self.data.iloc[idx, 1]\n",
    "#         # SuperClass = torch.tensor(SuperClass, dtype=torch.long)\n",
    "#         SubClass = self.data.iloc[idx, 3]\n",
    "#         if self.transform:\n",
    "#             image = self.transform(image)\n",
    "#         image = asarray(image)\n",
    "#         return (image, SuperClass, SubClass)\n",
    "\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.Resize((256,256)),\n",
    "#     transforms.ToTensor(),\n",
    "# ])\n",
    "\n",
    "# dataset = ImageDataset(csv_file='csv windows.csv', transform=transform)\n",
    "# images = [x[0] for x in dataset]\n",
    "# superclass_labels = [x[1] for x in dataset]\n",
    "# subclass_labels = [x[2] for x in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# # Serialize and save the list to a file\n",
    "# with open('image_list.pkl', 'wb') as f:\n",
    "#     pickle.dump(images, f)\n",
    "\n",
    "# with open('superclass_labels.pkl', 'wb') as f:\n",
    "#     pickle.dump(superclass_labels, f)\n",
    "    \n",
    "\n",
    "# with open('subclass_labels.pkl', 'wb') as f:\n",
    "#     pickle.dump(subclass_labels, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_pathimages = '/home/cpatel/superclass/data/images/images/image_list.pkl'\n",
    "\n",
    "with open(file_pathimages, 'rb') as f:\n",
    "    images = pickle.load(f)\n",
    "\n",
    "with open('superclass_labels.pkl', 'rb') as f:\n",
    "    superclass_labels = pickle.load(f)\n",
    "\n",
    "with open('subclass_labels.pkl', 'rb') as f:\n",
    "    subclass_labels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test, z_train, z_test = train_test_split(images, superclass_labels, subclass_labels, test_size=0.3, stratify=superclass_labels, random_state=42)\n",
    "x_train, x_val, y_train, y_val, z_train, z_val = train_test_split(x_train, y_train, z_train, test_size=0.3, stratify=y_train, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: Train=226, Val=107, Test=111\n",
      "Class 1: Train=484, Val=211, Test=319\n",
      "Class 2: Train=282, Val=111, Test=176\n",
      "Class 3: Train=223, Val=92, Test=138\n",
      "Class 4: Train=1700, Val=737, Test=1014\n",
      "Class 5: Train=284, Val=128, Test=214\n",
      "Class 6: Train=408, Val=175, Test=209\n",
      "Class 7: Train=268, Val=100, Test=192\n"
     ]
    }
   ],
   "source": [
    "# get the unique labels in y\n",
    "unique_labels = np.unique(subclass_labels)\n",
    "\n",
    "# count the number of samples in each set for each class\n",
    "train_counts = [np.sum(z_train == label) for label in unique_labels]\n",
    "val_counts = [np.sum(z_val == label) for label in unique_labels]\n",
    "test_counts = [np.sum(z_test == label) for label in unique_labels]\n",
    "\n",
    "# print the counts for each class in each set\n",
    "for i, label in enumerate(unique_labels): \n",
    "    print(f\"Class {label}: Train={train_counts[i]}, Val={val_counts[i]}, Test={test_counts[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class YourDataset(Dataset):\n",
    "    def __init__(self, x, y, z):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.z = z\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index], self.z[index]\n",
    "\n",
    "train_dataset = YourDataset(x_train, y_train, z_train)\n",
    "val_dataset = YourDataset(x_val, y_val, z_val)\n",
    "test_dataset = YourDataset(x_test, y_test, z_test)\n",
    "\n",
    "subclass_labels = torch.tensor(z_train)\n",
    "subclasses = torch.unique(subclass_labels)\n",
    "subclass_freqs = []\n",
    "\n",
    "for subclass in subclasses:\n",
    "    subclass_counts = sum(subclass_labels == subclass)\n",
    "    subclass_freqs.append(1/subclass_counts)\n",
    "\n",
    "subclass_weights = torch.zeros_like(subclass_labels).float()\n",
    "\n",
    "for idx, label in enumerate(subclass_labels):\n",
    "    subclass_weights[idx] = subclass_freqs[int(label)]\n",
    "\n",
    "sampler = WeightedRandomSampler(subclass_weights, len(subclass_weights))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16,sampler=sampler)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cpatel54\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "model = torchvision.models.resnet50(weights=True)\n",
    "\n",
    "lt=10\n",
    "cntr = 0\n",
    "for child in model.children():\n",
    "    cntr+=1\n",
    "\n",
    "    if cntr < lt:\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = torch.nn.Linear(in_features = num_ftrs, out_features = 1, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer and loss function\n",
    "\n",
    "# define cnn model\n",
    "model =  model.to(device)\n",
    "\n",
    "# define optimizer\n",
    "optimizer = Adam(model.parameters(), lr = 0.0001)\n",
    "\n",
    "# define loss function\n",
    "criterion = BCEWithLogitsLoss()\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the model\n",
    "def train(epoch):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    tr_loss=0\n",
    "    model.train()\n",
    "    \n",
    "    nb_classes = 2\n",
    "    confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "    num_subclasses = 8\n",
    "    num_samples = np.zeros(num_subclasses)\n",
    "    subgroup_correct = np.zeros(num_subclasses)\n",
    "    subgroup_correct_total = 0\n",
    "\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels, subclass = data\n",
    "        inputs = inputs.float()\n",
    "        labels = labels.float()\n",
    "        # print(labels)\n",
    "        # print(subclass)\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # predcition for training set\n",
    "        outputs = model(inputs)\n",
    "        # print(outputs)\n",
    "        \n",
    "        outputs = outputs.flatten()\n",
    "        total += labels.size(0)\n",
    "        # print(total)\n",
    "        \n",
    "        y_2 = torch.zeros(len(outputs))\n",
    "        y_2[outputs>=0.0] = 1\n",
    "        y_2= y_2.int()\n",
    "\n",
    "        y_2 = y_2.to(device)\n",
    "        \n",
    "        for subclasses in range(num_subclasses):\n",
    "            subclass_idx = subclass == subclasses\n",
    "            num_samples[subclasses] += torch.sum(subclass_idx)\n",
    "            subgroup_correct[subclasses] += ((y_2[subclass_idx] == labels[subclass_idx]).type(\n",
    "                torch.float).sum().item())\n",
    "            \n",
    "        subgroup_accuracy = subgroup_correct / num_samples\n",
    "        # print(y_2)\n",
    "        correct += (y_2 == labels).sum().item()\n",
    "        train_accuracy = correct / total \n",
    "        # for t, p in zip(labels.view(-1), y_2.view(-1)):\n",
    "        #         confusion_matrix[t.long(), p.long()] += 1\n",
    "        \n",
    "        # clearing the gradients of the model parameters\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # compute loss\n",
    "        q = torch.tensor([])\n",
    "        eta = 0.01\n",
    "        normalize_loss=False\n",
    "        batch_size = inputs.shape[0]\n",
    "        \n",
    "        if len(q) == 0:\n",
    "            q = torch.ones(num_subclasses).to(device)\n",
    "            q /= q.sum()\n",
    "\n",
    "        losses = torch.zeros(num_subclasses).to(device)\n",
    "\n",
    "        subclass_counts = torch.zeros(num_subclasses).to(device)\n",
    "        \n",
    "        # computes gDRO loss\n",
    "        # get relative frequency of samples in each subclass\n",
    "        for subclasses in range(num_subclasses):\n",
    "            subclass_idx = subclass == subclasses\n",
    "            subclass_counts[subclasses] = torch.sum(subclass_idx)\n",
    "\n",
    "            # only compute loss if there are actually samples in that class\n",
    "            if torch.sum(subclass_idx) > 0:\n",
    "                losses[subclasses] = criterion(outputs[subclass_idx], labels[subclass_idx])\n",
    "\n",
    "        # update q\n",
    "        if model.training:\n",
    "            q *= torch.exp(eta * losses.data)\n",
    "            q /= q.sum()\n",
    "\n",
    "        if normalize_loss:\n",
    "            losses *= subclass_counts\n",
    "            loss = torch.dot(losses, q)\n",
    "            loss /= batch_size\n",
    "            loss *= num_subclasses\n",
    "        else:\n",
    "            loss = torch.dot(losses, q)\n",
    "        # print(loss)\n",
    "        # compute updates weights of all the parameters\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        tr_loss += loss.item()\n",
    "\n",
    "    # Calculate training loss value\n",
    "    train_loss_value = tr_loss/len(train_loader) \n",
    "    # print(\"Epoch: {:.3f}, Loss: {:.3f}, Train_Accuracy: {:.3f}\".format(epoch+1, train_loss_value, train_accuracy)) \n",
    "    # print('confusion matrix of training images: {}'.format(confusion_matrix))\n",
    "    print(\"Epoch: {:.3f}, Loss: {:.3f}, Train_Accuracy: {:.3f}\".format(epoch+1, train_loss_value, train_accuracy)) \n",
    "    # print(\"Train Accuracy:\", accuracy, \"\\nTrain Accuracy over subgroups:\", subgroup_accuracy, \"\\nTrain Worst Group Accuracy:\",\n",
    "    #           min(subgroup_accuracy))\n",
    "    \n",
    "    return train_loss_value, train_accuracy, subgroup_accuracy \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(epoch):\n",
    "    \n",
    "    model.eval()\n",
    "    nb_classes = 2\n",
    "    confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "    num_subclasses = 8\n",
    "    num_samples = np.zeros(num_subclasses)\n",
    "    subgroup_correct = np.zeros(num_subclasses)\n",
    "    subgroup_correct_total = 0\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        tr_loss = 0\n",
    "        for i, data in enumerate(val_loader):\n",
    "            inputs, labels,subclass = data\n",
    "            inputs = inputs.float()\n",
    "            labels = labels.float()\n",
    "            # print(labels)\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # predcition for training set\n",
    "            outputs = model(inputs)\n",
    "            # print(outputs)\n",
    "            \n",
    "            outputs = outputs.flatten()\n",
    "            total += labels.size(0)\n",
    "            # print(total)\n",
    "            \n",
    "            loss_val = criterion(outputs, labels)\n",
    "            val_loss += loss_val.item()\n",
    "            val_loss_value = val_loss/len(val_loader)\n",
    "            \n",
    "            y_2 = torch.zeros(len(outputs))\n",
    "            y_2[outputs>=0.0] = 1\n",
    "            y_2 = y_2.int()\n",
    "            y_2 = y_2.to(device)\n",
    "            for subclasses in range(num_subclasses):\n",
    "                subclass_idx = subclass == subclasses\n",
    "                num_samples[subclasses] += torch.sum(subclass_idx)\n",
    "                subgroup_correct[subclasses] += (y_2[subclass_idx] == labels[subclass_idx]).type(\n",
    "                    torch.float).sum().item()\n",
    "\n",
    "            subgroup_accuracy = subgroup_correct / num_samples\n",
    "\n",
    "            for t, p in zip(labels.view(-1), y_2.view(-1)):\n",
    "                    confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "            \n",
    "            correct += (y_2 == labels).sum().item()\n",
    "            val_accuracy = correct / total\n",
    "            \n",
    "        # print(\"Epoch: {:.3f},  Val Accuracy: {:.3f}\".format(epoch+1,  val_accuracy))\n",
    "        print(\"Epoch: {:.3f}, Loss: {:.3f}, Val Accuracy: {:.3f}\".format(epoch+1, val_loss_value, val_accuracy)) \n",
    "        # print('confusion matrix of validation images: {}'.format(confusion_matrix)) \n",
    "        # print(\"Val Accuracy:\", accuracy, \"\\nVal Accuracy over subgroups:\", subgroup_accuracy, \"\\nVal Worst Group Accuracy:\",\n",
    "        #       min(subgroup_accuracy))       \n",
    "    \n",
    "        return val_accuracy, subgroup_accuracy, val_loss_value\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    \n",
    "    model.eval()\n",
    "    nb_classes = 2\n",
    "    confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "    subgroup_correct_total = 0\n",
    "    test_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        tr_loss = 0\n",
    "        num_subclasses = 8\n",
    "        num_samples = np.zeros(num_subclasses)\n",
    "        subgroup_correct = np.zeros(num_subclasses)\n",
    "        for i, data in enumerate(test_loader):\n",
    "            inputs, labels,subclass = data\n",
    "            inputs = inputs.float()\n",
    "            labels = labels.float()\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # print(labels)\n",
    "            \n",
    "            # predcition for training set\n",
    "            outputs = model(inputs)\n",
    "            # print(outputs)\n",
    "            \n",
    "            outputs = outputs.flatten()\n",
    "            total += labels.size(0)\n",
    "            # print(total)\n",
    "            \n",
    "            loss_train = criterion(outputs, labels)\n",
    "            test_loss += loss_train.item()\n",
    "            test_loss_value = test_loss/len(test_loader)\n",
    "            \n",
    "            y_2 = torch.zeros(len(outputs))\n",
    "            y_2[outputs>=0.0] = 1\n",
    "            y_2 = y_2.int()\n",
    "            y_2 = y_2.to(device)\n",
    "            # print(y_2)\n",
    "            for subclasses in range(num_subclasses):\n",
    "                subclass_idx = subclass == subclasses\n",
    "                num_samples[subclasses] += torch.sum(subclass_idx)\n",
    "                subgroup_correct[subclasses] += (y_2[subclass_idx] == labels[subclass_idx]).type(\n",
    "                    torch.float).sum().item()\n",
    "\n",
    "            subgroup_accuracy = subgroup_correct / num_samples\n",
    "\n",
    "            \n",
    "            for t, p in zip(labels.view(-1), y_2.view(-1)):\n",
    "                    confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "            \n",
    "            correct += (y_2 == labels).sum().item()\n",
    "            test_accuracy = correct / total\n",
    "            \n",
    "        print(\"Epoch: {:.3f}, Loss: {:.3f}, Test Accuracy: {:.3f}\".format(epoch+1, test_loss_value, test_accuracy)) \n",
    "        # print('confusion matrix of testing images: {}'.format(confusion_matrix))\n",
    "        # print(\"Test Accuracy:\", test_accuracy, \"\\nTest Accuracy over subgroups:\", subgroup_accuracy, \"\\nTest Worst Group Accuracy:\",\n",
    "            #  min(subgroup_accuracy)) \n",
    "   \n",
    "        return test_accuracy, subgroup_accuracy, test_loss_value\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cpatel54\\AppData\\Local\\Temp\\ipykernel_16520\\3406275876.py:44: RuntimeWarning: invalid value encountered in divide\n",
      "  subgroup_accuracy = subgroup_correct / num_samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1.000, Loss: 0.534, Train_Accuracy: 0.708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cpatel54\\AppData\\Local\\Temp\\ipykernel_16520\\3435729575.py:45: RuntimeWarning: invalid value encountered in divide\n",
      "  subgroup_accuracy = subgroup_correct / num_samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1.000,  Val Accuracy: 0.840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cpatel54\\AppData\\Local\\Temp\\ipykernel_16520\\2686407693.py:47: RuntimeWarning: invalid value encountered in divide\n",
      "  subgroup_accuracy = subgroup_correct / num_samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1.000, Test Accuracy: 0.842\n",
      "Epoch: 2.000, Loss: 0.439, Train_Accuracy: 0.812\n",
      "Epoch: 2.000,  Val Accuracy: 0.854\n",
      "Epoch: 2.000, Test Accuracy: 0.856\n",
      "Epoch: 3.000, Loss: 0.384, Train_Accuracy: 0.825\n",
      "Epoch: 3.000,  Val Accuracy: 0.860\n",
      "Epoch: 3.000, Test Accuracy: 0.866\n",
      "Epoch: 4.000, Loss: 0.358, Train_Accuracy: 0.835\n",
      "Epoch: 4.000,  Val Accuracy: 0.879\n",
      "Epoch: 4.000, Test Accuracy: 0.881\n",
      "Epoch: 5.000, Loss: 0.334, Train_Accuracy: 0.843\n",
      "Epoch: 5.000,  Val Accuracy: 0.852\n",
      "Epoch: 5.000, Test Accuracy: 0.858\n",
      "Epoch: 6.000, Loss: 0.325, Train_Accuracy: 0.847\n",
      "Epoch: 6.000,  Val Accuracy: 0.876\n",
      "Epoch: 6.000, Test Accuracy: 0.885\n",
      "Epoch: 7.000, Loss: 0.310, Train_Accuracy: 0.860\n",
      "Epoch: 7.000,  Val Accuracy: 0.878\n",
      "Epoch: 7.000, Test Accuracy: 0.894\n",
      "Epoch: 8.000, Loss: 0.307, Train_Accuracy: 0.856\n",
      "Epoch: 8.000,  Val Accuracy: 0.877\n",
      "Epoch: 8.000, Test Accuracy: 0.891\n",
      "Epoch: 9.000, Loss: 0.299, Train_Accuracy: 0.858\n",
      "Epoch: 9.000,  Val Accuracy: 0.868\n",
      "Epoch: 9.000, Test Accuracy: 0.876\n",
      "Epoch: 10.000, Loss: 0.308, Train_Accuracy: 0.846\n",
      "Epoch: 10.000,  Val Accuracy: 0.874\n",
      "Epoch: 10.000, Test Accuracy: 0.893\n",
      "Epoch: 11.000, Loss: 0.296, Train_Accuracy: 0.862\n",
      "Epoch: 11.000,  Val Accuracy: 0.877\n",
      "Epoch: 11.000, Test Accuracy: 0.893\n",
      "Epoch: 12.000, Loss: 0.288, Train_Accuracy: 0.855\n",
      "Epoch: 12.000,  Val Accuracy: 0.884\n",
      "Epoch: 12.000, Test Accuracy: 0.896\n",
      "Epoch: 13.000, Loss: 0.278, Train_Accuracy: 0.872\n",
      "Epoch: 13.000,  Val Accuracy: 0.877\n",
      "Epoch: 13.000, Test Accuracy: 0.899\n",
      "Epoch: 14.000, Loss: 0.281, Train_Accuracy: 0.869\n",
      "Epoch: 14.000,  Val Accuracy: 0.886\n",
      "Epoch: 14.000, Test Accuracy: 0.901\n",
      "Epoch: 15.000, Loss: 0.270, Train_Accuracy: 0.866\n",
      "Epoch: 15.000,  Val Accuracy: 0.893\n",
      "Epoch: 15.000, Test Accuracy: 0.902\n",
      "Epoch: 16.000, Loss: 0.277, Train_Accuracy: 0.862\n",
      "Epoch: 16.000,  Val Accuracy: 0.885\n",
      "Epoch: 16.000, Test Accuracy: 0.895\n",
      "Epoch: 17.000, Loss: 0.252, Train_Accuracy: 0.875\n",
      "Epoch: 17.000,  Val Accuracy: 0.884\n",
      "Epoch: 17.000, Test Accuracy: 0.893\n",
      "Epoch: 18.000, Loss: 0.255, Train_Accuracy: 0.875\n",
      "Epoch: 18.000,  Val Accuracy: 0.883\n",
      "Epoch: 18.000, Test Accuracy: 0.895\n",
      "Epoch: 19.000, Loss: 0.267, Train_Accuracy: 0.870\n",
      "Epoch: 19.000,  Val Accuracy: 0.875\n",
      "Epoch: 19.000, Test Accuracy: 0.890\n",
      "Epoch: 20.000, Loss: 0.279, Train_Accuracy: 0.865\n",
      "Epoch: 20.000,  Val Accuracy: 0.886\n",
      "Epoch: 20.000, Test Accuracy: 0.901\n",
      "Epoch: 21.000, Loss: 0.272, Train_Accuracy: 0.863\n",
      "Epoch: 21.000,  Val Accuracy: 0.895\n",
      "Epoch: 21.000, Test Accuracy: 0.906\n",
      "Epoch: 22.000, Loss: 0.271, Train_Accuracy: 0.872\n",
      "Epoch: 22.000,  Val Accuracy: 0.881\n",
      "Epoch: 22.000, Test Accuracy: 0.886\n",
      "Epoch: 23.000, Loss: 0.264, Train_Accuracy: 0.868\n",
      "Epoch: 23.000,  Val Accuracy: 0.896\n",
      "Epoch: 23.000, Test Accuracy: 0.906\n",
      "Epoch: 24.000, Loss: 0.262, Train_Accuracy: 0.874\n",
      "Epoch: 24.000,  Val Accuracy: 0.896\n",
      "Epoch: 24.000, Test Accuracy: 0.909\n",
      "Epoch: 25.000, Loss: 0.256, Train_Accuracy: 0.878\n",
      "Epoch: 25.000,  Val Accuracy: 0.893\n",
      "Epoch: 25.000, Test Accuracy: 0.902\n",
      "Epoch: 26.000, Loss: 0.251, Train_Accuracy: 0.879\n",
      "Epoch: 26.000,  Val Accuracy: 0.887\n",
      "Epoch: 26.000, Test Accuracy: 0.895\n",
      "Epoch: 27.000, Loss: 0.241, Train_Accuracy: 0.888\n",
      "Epoch: 27.000,  Val Accuracy: 0.890\n",
      "Epoch: 27.000, Test Accuracy: 0.898\n",
      "Epoch: 28.000, Loss: 0.251, Train_Accuracy: 0.880\n",
      "Epoch: 28.000,  Val Accuracy: 0.894\n",
      "Epoch: 28.000, Test Accuracy: 0.900\n",
      "Epoch: 29.000, Loss: 0.233, Train_Accuracy: 0.885\n",
      "Epoch: 29.000,  Val Accuracy: 0.889\n",
      "Epoch: 29.000, Test Accuracy: 0.899\n",
      "Epoch: 30.000, Loss: 0.257, Train_Accuracy: 0.876\n",
      "Epoch: 30.000,  Val Accuracy: 0.899\n",
      "Epoch: 30.000, Test Accuracy: 0.904\n",
      "Epoch: 31.000, Loss: 0.237, Train_Accuracy: 0.886\n",
      "Epoch: 31.000,  Val Accuracy: 0.890\n",
      "Epoch: 31.000, Test Accuracy: 0.904\n",
      "Epoch: 32.000, Loss: 0.248, Train_Accuracy: 0.878\n",
      "Epoch: 32.000,  Val Accuracy: 0.895\n",
      "Epoch: 32.000, Test Accuracy: 0.903\n",
      "Epoch: 33.000, Loss: 0.257, Train_Accuracy: 0.867\n",
      "Epoch: 33.000,  Val Accuracy: 0.893\n",
      "Epoch: 33.000, Test Accuracy: 0.905\n",
      "Epoch: 34.000, Loss: 0.247, Train_Accuracy: 0.879\n",
      "Epoch: 34.000,  Val Accuracy: 0.903\n",
      "Epoch: 34.000, Test Accuracy: 0.907\n",
      "Epoch: 35.000, Loss: 0.248, Train_Accuracy: 0.878\n",
      "Epoch: 35.000,  Val Accuracy: 0.895\n",
      "Epoch: 35.000, Test Accuracy: 0.903\n",
      "Epoch: 36.000, Loss: 0.242, Train_Accuracy: 0.877\n",
      "Epoch: 36.000,  Val Accuracy: 0.898\n",
      "Epoch: 36.000, Test Accuracy: 0.907\n",
      "Epoch: 37.000, Loss: 0.249, Train_Accuracy: 0.876\n",
      "Epoch: 37.000,  Val Accuracy: 0.890\n",
      "Epoch: 37.000, Test Accuracy: 0.898\n",
      "Epoch: 38.000, Loss: 0.235, Train_Accuracy: 0.883\n",
      "Epoch: 38.000,  Val Accuracy: 0.886\n",
      "Epoch: 38.000, Test Accuracy: 0.897\n",
      "Epoch: 39.000, Loss: 0.236, Train_Accuracy: 0.886\n",
      "Epoch: 39.000,  Val Accuracy: 0.898\n",
      "Epoch: 39.000, Test Accuracy: 0.909\n",
      "Epoch: 40.000, Loss: 0.236, Train_Accuracy: 0.881\n",
      "Epoch: 40.000,  Val Accuracy: 0.899\n",
      "Epoch: 40.000, Test Accuracy: 0.900\n",
      "Epoch: 41.000, Loss: 0.243, Train_Accuracy: 0.880\n",
      "Epoch: 41.000,  Val Accuracy: 0.896\n",
      "Epoch: 41.000, Test Accuracy: 0.901\n",
      "Epoch: 42.000, Loss: 0.244, Train_Accuracy: 0.884\n",
      "Epoch: 42.000,  Val Accuracy: 0.899\n",
      "Epoch: 42.000, Test Accuracy: 0.899\n",
      "Epoch: 43.000, Loss: 0.234, Train_Accuracy: 0.893\n",
      "Epoch: 43.000,  Val Accuracy: 0.891\n",
      "Epoch: 43.000, Test Accuracy: 0.898\n",
      "Epoch: 44.000, Loss: 0.229, Train_Accuracy: 0.891\n",
      "Epoch: 44.000,  Val Accuracy: 0.898\n",
      "Epoch: 44.000, Test Accuracy: 0.902\n",
      "Epoch: 45.000, Loss: 0.235, Train_Accuracy: 0.887\n",
      "Epoch: 45.000,  Val Accuracy: 0.899\n",
      "Epoch: 45.000, Test Accuracy: 0.903\n",
      "Epoch: 46.000, Loss: 0.225, Train_Accuracy: 0.888\n",
      "Epoch: 46.000,  Val Accuracy: 0.898\n",
      "Epoch: 46.000, Test Accuracy: 0.906\n",
      "Epoch: 47.000, Loss: 0.234, Train_Accuracy: 0.884\n",
      "Epoch: 47.000,  Val Accuracy: 0.891\n",
      "Epoch: 47.000, Test Accuracy: 0.895\n",
      "Epoch: 48.000, Loss: 0.235, Train_Accuracy: 0.879\n",
      "Epoch: 48.000,  Val Accuracy: 0.901\n",
      "Epoch: 48.000, Test Accuracy: 0.911\n",
      "Epoch: 49.000, Loss: 0.236, Train_Accuracy: 0.887\n",
      "Epoch: 49.000,  Val Accuracy: 0.899\n",
      "Epoch: 49.000, Test Accuracy: 0.898\n",
      "Epoch: 50.000, Loss: 0.233, Train_Accuracy: 0.885\n",
      "Epoch: 50.000,  Val Accuracy: 0.896\n",
      "Epoch: 50.000, Test Accuracy: 0.903\n",
      "Epoch: 51.000, Loss: 0.237, Train_Accuracy: 0.883\n",
      "Epoch: 51.000,  Val Accuracy: 0.895\n",
      "Epoch: 51.000, Test Accuracy: 0.904\n",
      "Epoch: 52.000, Loss: 0.233, Train_Accuracy: 0.886\n",
      "Epoch: 52.000,  Val Accuracy: 0.901\n",
      "Epoch: 52.000, Test Accuracy: 0.908\n",
      "Epoch: 53.000, Loss: 0.229, Train_Accuracy: 0.889\n",
      "Epoch: 53.000,  Val Accuracy: 0.905\n",
      "Epoch: 53.000, Test Accuracy: 0.910\n",
      "Epoch: 54.000, Loss: 0.231, Train_Accuracy: 0.884\n",
      "Epoch: 54.000,  Val Accuracy: 0.895\n",
      "Epoch: 54.000, Test Accuracy: 0.903\n",
      "Epoch: 55.000, Loss: 0.222, Train_Accuracy: 0.889\n",
      "Epoch: 55.000,  Val Accuracy: 0.902\n",
      "Epoch: 55.000, Test Accuracy: 0.909\n",
      "Epoch: 56.000, Loss: 0.218, Train_Accuracy: 0.890\n",
      "Epoch: 56.000,  Val Accuracy: 0.899\n",
      "Epoch: 56.000, Test Accuracy: 0.905\n",
      "Epoch: 57.000, Loss: 0.216, Train_Accuracy: 0.893\n",
      "Epoch: 57.000,  Val Accuracy: 0.892\n",
      "Epoch: 57.000, Test Accuracy: 0.898\n",
      "Epoch: 58.000, Loss: 0.232, Train_Accuracy: 0.887\n",
      "Epoch: 58.000,  Val Accuracy: 0.903\n",
      "Epoch: 58.000, Test Accuracy: 0.909\n",
      "Epoch: 59.000, Loss: 0.222, Train_Accuracy: 0.889\n",
      "Epoch: 59.000,  Val Accuracy: 0.896\n",
      "Epoch: 59.000, Test Accuracy: 0.907\n",
      "Epoch: 60.000, Loss: 0.216, Train_Accuracy: 0.896\n",
      "Epoch: 60.000,  Val Accuracy: 0.902\n",
      "Epoch: 60.000, Test Accuracy: 0.912\n",
      "Epoch: 61.000, Loss: 0.224, Train_Accuracy: 0.893\n",
      "Epoch: 61.000,  Val Accuracy: 0.910\n",
      "Epoch: 61.000, Test Accuracy: 0.913\n",
      "Epoch: 62.000, Loss: 0.220, Train_Accuracy: 0.888\n",
      "Epoch: 62.000,  Val Accuracy: 0.894\n",
      "Epoch: 62.000, Test Accuracy: 0.902\n",
      "Epoch: 63.000, Loss: 0.211, Train_Accuracy: 0.897\n",
      "Epoch: 63.000,  Val Accuracy: 0.899\n",
      "Epoch: 63.000, Test Accuracy: 0.903\n",
      "Epoch: 64.000, Loss: 0.226, Train_Accuracy: 0.888\n",
      "Epoch: 64.000,  Val Accuracy: 0.898\n",
      "Epoch: 64.000, Test Accuracy: 0.897\n",
      "Epoch: 65.000, Loss: 0.221, Train_Accuracy: 0.889\n",
      "Epoch: 65.000,  Val Accuracy: 0.893\n",
      "Epoch: 65.000, Test Accuracy: 0.895\n",
      "Epoch: 66.000, Loss: 0.225, Train_Accuracy: 0.896\n",
      "Epoch: 66.000,  Val Accuracy: 0.899\n",
      "Epoch: 66.000, Test Accuracy: 0.901\n",
      "Epoch: 67.000, Loss: 0.235, Train_Accuracy: 0.885\n",
      "Epoch: 67.000,  Val Accuracy: 0.892\n",
      "Epoch: 67.000, Test Accuracy: 0.902\n",
      "Epoch: 68.000, Loss: 0.207, Train_Accuracy: 0.900\n",
      "Epoch: 68.000,  Val Accuracy: 0.903\n",
      "Epoch: 68.000, Test Accuracy: 0.909\n",
      "For Trial: 0 Test Accuracy: 0.9089759797724399 \n",
      "Test Accuracy over each subgroups: [0.89189189 0.84952978 0.88068182 0.9057971  0.93491124 0.91121495\n",
      " 0.9138756  0.90104167] \n",
      "test Worst Group Accuracy: 0.8495297805642633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cpatel54\\AppData\\Local\\Temp\\ipykernel_16520\\3623830998.py:35: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df1 = df1.append({'trial': i, 'subtype': j, 'Train gDRO accuracy': acc}, ignore_index=True)\n",
      "C:\\Users\\cpatel54\\AppData\\Local\\Temp\\ipykernel_16520\\3623830998.py:35: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df1 = df1.append({'trial': i, 'subtype': j, 'Train gDRO accuracy': acc}, ignore_index=True)\n",
      "C:\\Users\\cpatel54\\AppData\\Local\\Temp\\ipykernel_16520\\3623830998.py:35: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df1 = df1.append({'trial': i, 'subtype': j, 'Train gDRO accuracy': acc}, ignore_index=True)\n",
      "C:\\Users\\cpatel54\\AppData\\Local\\Temp\\ipykernel_16520\\3623830998.py:35: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df1 = df1.append({'trial': i, 'subtype': j, 'Train gDRO accuracy': acc}, ignore_index=True)\n",
      "C:\\Users\\cpatel54\\AppData\\Local\\Temp\\ipykernel_16520\\3623830998.py:35: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df1 = df1.append({'trial': i, 'subtype': j, 'Train gDRO accuracy': acc}, ignore_index=True)\n",
      "C:\\Users\\cpatel54\\AppData\\Local\\Temp\\ipykernel_16520\\3623830998.py:35: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df1 = df1.append({'trial': i, 'subtype': j, 'Train gDRO accuracy': acc}, ignore_index=True)\n",
      "C:\\Users\\cpatel54\\AppData\\Local\\Temp\\ipykernel_16520\\3623830998.py:35: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df1 = df1.append({'trial': i, 'subtype': j, 'Train gDRO accuracy': acc}, ignore_index=True)\n",
      "C:\\Users\\cpatel54\\AppData\\Local\\Temp\\ipykernel_16520\\3623830998.py:35: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df1 = df1.append({'trial': i, 'subtype': j, 'Train gDRO accuracy': acc}, ignore_index=True)\n",
      "C:\\Users\\cpatel54\\AppData\\Local\\Temp\\ipykernel_16520\\3623830998.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df1 = df1.append({'trial': i, 'subtype': 'overall', 'Train gDRO accuracy': temptrain_acc}, ignore_index=True)\n",
      "C:\\Users\\cpatel54\\AppData\\Local\\Temp\\ipykernel_16520\\3623830998.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append({'trial': i, 'subtype': j, 'Val gDRO accuracy': acc}, ignore_index=True)\n",
      "C:\\Users\\cpatel54\\AppData\\Local\\Temp\\ipykernel_16520\\3623830998.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append({'trial': i, 'subtype': j, 'Val gDRO accuracy': acc}, ignore_index=True)\n",
      "C:\\Users\\cpatel54\\AppData\\Local\\Temp\\ipykernel_16520\\3623830998.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append({'trial': i, 'subtype': j, 'Val gDRO accuracy': acc}, ignore_index=True)\n",
      "C:\\Users\\cpatel54\\AppData\\Local\\Temp\\ipykernel_16520\\3623830998.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append({'trial': i, 'subtype': j, 'Val gDRO accuracy': acc}, ignore_index=True)\n",
      "C:\\Users\\cpatel54\\AppData\\Local\\Temp\\ipykernel_16520\\3623830998.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append({'trial': i, 'subtype': j, 'Val gDRO accuracy': acc}, ignore_index=True)\n",
      "C:\\Users\\cpatel54\\AppData\\Local\\Temp\\ipykernel_16520\\3623830998.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append({'trial': i, 'subtype': j, 'Val gDRO accuracy': acc}, ignore_index=True)\n",
      "C:\\Users\\cpatel54\\AppData\\Local\\Temp\\ipykernel_16520\\3623830998.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append({'trial': i, 'subtype': j, 'Val gDRO accuracy': acc}, ignore_index=True)\n",
      "C:\\Users\\cpatel54\\AppData\\Local\\Temp\\ipykernel_16520\\3623830998.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append({'trial': i, 'subtype': j, 'Val gDRO accuracy': acc}, ignore_index=True)\n",
      "C:\\Users\\cpatel54\\AppData\\Local\\Temp\\ipykernel_16520\\3623830998.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append({'trial': i, 'subtype': 'overall', 'Val gDRO accuracy': tempval_acc}, ignore_index=True)\n",
      "C:\\Users\\cpatel54\\AppData\\Local\\Temp\\ipykernel_16520\\3623830998.py:47: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df3 = df3.append({'trial': i, 'subtype': j, 'Test gDRO accuracy': acc}, ignore_index=True)\n",
      "C:\\Users\\cpatel54\\AppData\\Local\\Temp\\ipykernel_16520\\3623830998.py:47: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df3 = df3.append({'trial': i, 'subtype': j, 'Test gDRO accuracy': acc}, ignore_index=True)\n",
      "C:\\Users\\cpatel54\\AppData\\Local\\Temp\\ipykernel_16520\\3623830998.py:47: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df3 = df3.append({'trial': i, 'subtype': j, 'Test gDRO accuracy': acc}, ignore_index=True)\n",
      "C:\\Users\\cpatel54\\AppData\\Local\\Temp\\ipykernel_16520\\3623830998.py:47: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df3 = df3.append({'trial': i, 'subtype': j, 'Test gDRO accuracy': acc}, ignore_index=True)\n",
      "C:\\Users\\cpatel54\\AppData\\Local\\Temp\\ipykernel_16520\\3623830998.py:47: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df3 = df3.append({'trial': i, 'subtype': j, 'Test gDRO accuracy': acc}, ignore_index=True)\n",
      "C:\\Users\\cpatel54\\AppData\\Local\\Temp\\ipykernel_16520\\3623830998.py:47: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df3 = df3.append({'trial': i, 'subtype': j, 'Test gDRO accuracy': acc}, ignore_index=True)\n",
      "C:\\Users\\cpatel54\\AppData\\Local\\Temp\\ipykernel_16520\\3623830998.py:47: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df3 = df3.append({'trial': i, 'subtype': j, 'Test gDRO accuracy': acc}, ignore_index=True)\n",
      "C:\\Users\\cpatel54\\AppData\\Local\\Temp\\ipykernel_16520\\3623830998.py:47: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df3 = df3.append({'trial': i, 'subtype': j, 'Test gDRO accuracy': acc}, ignore_index=True)\n",
      "C:\\Users\\cpatel54\\AppData\\Local\\Temp\\ipykernel_16520\\3623830998.py:50: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df3 = df3.append({'trial': i, 'subtype': 'overall', 'Test gDRO accuracy': temptest_acc}, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# number of epochs\n",
    "n_epochs = 4\n",
    "# tr_loss = []\n",
    "# tr_accuracies = []\n",
    "# val_loss = []\n",
    "# val_accuracies = []\n",
    "# test_loss = []\n",
    "# test_accuracies = []\n",
    "max_worst_accuracy = 0\n",
    "\n",
    "patience = 10\n",
    "best_val_loss = float('inf')\n",
    "num_trials = 1\n",
    "df1 = pd.DataFrame(columns=['trial', 'epochs', 'subtype', 'Train ERM accuracy', 'Train ERM loss'])\n",
    "df2 = pd.DataFrame(columns=['trial', 'epochs', 'subtype', 'Val ERM accuracy', 'Val ERM loss'])\n",
    "df3 = pd.DataFrame(columns=['trial', 'epochs', 'subtype', 'Test ERM accuracy', 'Test ERM loss'])\n",
    "minmax_acc_test = pd.DataFrame(columns=['trial', 'epochs', 'Min_subtype', 'Min subclass accuracy', 'Max_subtype', 'Max subclass accuracy'])\n",
    "\n",
    "subgroups = ['adenosis',\n",
    "            'fibroadenoma',\n",
    "            'tubular_adenoma',\n",
    "            'phyllodes_tumor',\n",
    "            'ductal_carcinoma',\n",
    "            'lobular_carcinoma',\n",
    "            'mucinous_carcinoma',\n",
    "            'papillary_carcinoma']\n",
    "\n",
    "# training the model\n",
    "for i in range(num_trials):\n",
    "    for epoch in range(n_epochs):\n",
    "        temptrain_acc, trainsubgroup_acc, train_loss = train(epoch)\n",
    "        tempval_acc, valsubgroup_acc, val_loss = val(epoch)\n",
    "        temptest_acc, testsubgroup_acc, test_loss = test(epoch)\n",
    "        \n",
    "        test_accuracies.append(temptest_acc)\n",
    "\n",
    "        \n",
    "        min_val = min(testsubgroup_acc)\n",
    "        min_index = testsubgroup_acc.argmin()\n",
    "        max_val = max(testsubgroup_acc)\n",
    "        max_index = testsubgroup_acc.argmax()\n",
    "        minmax_acc_test = minmax_acc_test.append({'trial': i, 'epochs': epoch, 'Min_subtype': min_index, 'Min subclass accuracy': min_val, 'Max_subtype': max_index, 'Max subclass accuracy': max_val}, ignore_index=True)\n",
    "        \n",
    "        # append accuracy values for each subgroup to the dataframes\n",
    "        for j, acc in zip(subgroups, trainsubgroup_acc):\n",
    "            df1 = df1.append({'trial': i, 'epochs': epoch, 'subtype': j, 'Train ERM accuracy': acc, 'Train ERM loss': train_loss}, ignore_index=True)\n",
    "        \n",
    "        # add overall accuracy to Train gDRO accuracy for each trial\n",
    "        df1 = df1.append({'trial': i, 'epochs': epoch, 'subtype': 'overall', 'Train ERM accuracy': temptrain_acc, 'Train ERM loss': train_loss}, ignore_index=True)\n",
    "        \n",
    "        for j, acc in zip(subgroups, valsubgroup_acc):\n",
    "            df2 = df2.append({'trial': i , 'epochs': epoch, 'subtype': j, 'Val ERM accuracy': acc, 'Val ERM loss': val_loss}, ignore_index=True)\n",
    "        \n",
    "        # add overall accuracy to Val gDRO accuracy for each trial\n",
    "        df2 = df2.append({'trial': i, 'epochs': epoch, 'subtype': 'overall', 'Val ERM accuracy': tempval_acc, 'Val ERM loss': val_loss}, ignore_index=True)\n",
    "        \n",
    "        for j, acc in zip(subgroups, testsubgroup_acc):\n",
    "            df3 = df3.append({'trial': i , 'epochs': epoch, 'subtype': j, 'Test ERM accuracy': acc, 'Test ERM loss': test_loss,},  ignore_index=True)\n",
    "            \n",
    "        # add overall accuracy to Test gDRO accuracy for each trial\n",
    "        df3 = df3.append({'trial': i,'epochs': epoch, 'subtype': 'overall', 'Test ERM accuracy': temptest_acc, 'Test ERM loss': test_loss}, ignore_index=True)\n",
    "\n",
    "        # Check if the validation loss has increased and update the best model if it hasn't\n",
    "        # a =  min(valsubgroup_acc)\n",
    "        # print(a)\n",
    "        # if a >= max_worst_accuracy:\n",
    "        #     max_worst_accuracy = a\n",
    "        #     best_epoch = epoch\n",
    "        #     print('I am saving the best dro model at Epoch: ', best_epoch)\n",
    "        #     torch.save(model.state_dict(), r'Best_gdromodel.pth')\n",
    "        #     counter = 0\n",
    "        # else:\n",
    "        #     counter += 1\n",
    "        #     if counter >= patience: # Stop early if the validation loss has increased for `patience` epochs\n",
    "        #         break\n",
    "     \n",
    "    # print(\"For Trial:\",i,\"Train Accuracy:\", temptrain_acc, \"\\nTrain Accuracy over each subgroups:\", trainsubgroup_acc, \"\\nTrain Worst Group Accuracy:\",min(trainsubgroup_acc))\n",
    "    # print(\"For Trial:\",i,\"Val Accuracy:\", tempval_acc, \"\\nVal Accuracy over each subgroups:\", valsubgroup_acc, \"\\nVal Worst Group Accuracy:\",min(valsubgroup_acc))\n",
    "    print(\"For Trial:\",i,\"Test Accuracy:\", temptest_acc,\"\\nTest Accuracy over each subgroups:\", testsubgroup_acc, \"\\ntest Worst Group Accuracy:\",min(testsubgroup_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assuming that df1 is your data frame\n",
    "df1.to_csv('Train_bc-gdro_imagenet.csv', index=False)\n",
    "df2.to_csv('Val_bc-gdro_imagenet.csv', index=False)\n",
    "df3.to_csv('Test_bc-gdro_imagenet.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
